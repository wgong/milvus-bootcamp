{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f53f753-12c6-4fac-b910-6e96677d8a49",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/use_cases/agents/langchain/langgraph-rag-agent-local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb22d58-3d9a-40bc-9f7f-7cbb74fab67b",
   "metadata": {},
   "source": [
    "on `gongai` desktop, \n",
    "\n",
    "```\n",
    "cd ~/projects/AI/milvus-io/milvus-bootcamp/bootcamp/RAG/advanced_rag\n",
    "conda activate rag\n",
    "pip install -U langchain_community tiktoken langchainhub pymilvus langchain langgraph tavily-python sentence-transformers langchain-milvus langchain-huggingface\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ab14a-fd80-4ca2-afc5-efe1c39532bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langchain_community tiktoken langchainhub pymilvus langchain langgraph tavily-python sentence-transformers langchain-milvus langchain-huggingface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0216de30-29cf-4464-9cc3-6e9a6d6c3e40",
   "metadata": {},
   "source": [
    "# Local LangGraph RAG agent with Llama 3\n",
    "\n",
    "\n",
    "Let's build an Advanced RAG that will run everything locally, for that we will use Ollama.\n",
    "\n",
    "## Ideas\n",
    "\n",
    "We'll combine ideas from three RAG papers into a RAG agent:\n",
    "\n",
    "- **Routing:**  Adaptive RAG ([paper](https://arxiv.org/abs/2403.14403)). Route questions to different retrieval approaches\n",
    "- **Fallback:** Corrective RAG ([paper](https://arxiv.org/pdf/2401.15884.pdf)). Fallback to web search if docs are not relevant to query\n",
    "- **Self-correction:** Self-RAG ([paper](https://arxiv.org/abs/2310.11511)). Fix answers w/ hallucinations or don’t address question\n",
    "\n",
    "![langgraph_adaptive_rag.png](imgs/RAG_Agent_langGraph.png)\n",
    "\n",
    "Note that this will incorperate [a few general ideas for agents](https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/):\n",
    "\n",
    "- **Reflection**: The self-correction mechanism is a form of reflection, where the LangGraph agent reflects on its retrieval and generations\n",
    "- **Planning**: The control flow laid out in the graph is a form of planning \n",
    "- **Tool use**: Specific nodes in the control flow (e.g., web search) will use tools\n",
    "\n",
    "## Local models\n",
    "\n",
    "### LLM\n",
    "\n",
    "Use [Ollama](https://ollama.ai/) and [llama3](https://ollama.ai/library/llama3):\n",
    "\n",
    "```\n",
    "ollama pull llama3\n",
    "```\n",
    "\n",
    "### Search\n",
    "\n",
    "Uses [Tavily](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2242c5-0dbb-4f21-9771-92f6d679b1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7892526-d832-4882-a97f-33de69c4a8e5",
   "metadata": {},
   "source": [
    "os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3897d23e-011f-469c-ad72-829c429e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2096d49c-d3dc-4329-ada7-aff56d210198",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "\n",
    "local_llm = 'llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426bef66-f978-4f1e-b3f7-c26acccc77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### Index\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4e059f2-f2a3-4729-a5ed-fac6397e574d",
   "metadata": {},
   "source": [
    "len(docs_list), docs_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19426238-e04d-4194-9d3f-93a735a29b8f",
   "metadata": {},
   "source": [
    "got error \n",
    "```\n",
    "ModuleNotFoundError: No module named 'langchain_milvus'\n",
    "```\n",
    "\n",
    "resolved by re-creating virtualenv `rag`\n",
    "```\n",
    "conda create -n rag python=3.11\n",
    "conda activate rag\n",
    "pip install -r requirements.txt\n",
    "jupyter lab\n",
    "\n",
    "```\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/retrievers/self_query/milvus_self_query/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2706bb9-bc31-42e5-bcbc-6c4be4d324af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gongai/anaconda3/envs/rag/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/gongai/anaconda3/envs/rag/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/gongai/anaconda3/envs/rag/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Add to Milvus\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag_milvus\",\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    connection_args={\"uri\": \"./milvus_rag.db\"},\n",
    "\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b008df98-8394-49da-8fb8-aefe2c90d03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"document\": \"Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"document\": \"Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n    \\n    Here is the user question: \\n    agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [10.14s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:37:09.347333193Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 10138337044,\n",
      "          \"load_duration\": 763783323,\n",
      "          \"prompt_eval_count\": 360,\n",
      "          \"prompt_eval_duration\": 8315413000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1005631000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:37:09.347333193Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 10138337044,\n",
      "              \"load_duration\": 763783323,\n",
      "              \"prompt_eval_count\": 360,\n",
      "              \"prompt_eval_duration\": 8315413000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1005631000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b1c11ede-7937-4846-bda2-24ff131719e6-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [10.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n",
    "    \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     \n",
    "    Here is the retrieved document: \n",
    "    {document}\n",
    "    \n",
    "    Here is the user question: \n",
    "    {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d531a81-6d4d-405e-975a-01ef1c9679fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: agent memory \\n    Context: [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320867}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320889}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320832}, page_content=\\\"LLM Powered Autonomous Agents | Lil'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLil'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPosts\\\\n\\\\n\\\\n\\\\n\\\\nArchive\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\nTags\\\\n\\\\n\\\\n\\\\n\\\\nFAQ\\\\n\\\\n\\\\n\\\\n\\\\nemojisearch.app\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n      LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\n \\\\n\\\\n\\\\nTable of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320866}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\\\nGenerative Agents Simulation#\\\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\\\n\\\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.')] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [61.44s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:38:40.48396813Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61442635338,\n",
      "          \"load_duration\": 1253998,\n",
      "          \"prompt_eval_count\": 1662,\n",
      "          \"prompt_eval_duration\": 52897912000,\n",
      "          \"eval_count\": 48,\n",
      "          \"eval_duration\": 8400444000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:38:40.48396813Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61442635338,\n",
      "              \"load_duration\": 1253998,\n",
      "              \"prompt_eval_count\": 1662,\n",
      "              \"prompt_eval_duration\": 52897912000,\n",
      "              \"eval_count\": 48,\n",
      "              \"eval_duration\": 8400444000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4b81d190-9e3e-4d63-8d1d-8a801f5f9487-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [61.45s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\"\n",
      "}\n",
      "According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0261a9a4-de13-4dd8-b082-95305a3e43ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320867}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320889}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320832}, page_content=\\\"LLM Powered Autonomous Agents | Lil'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLil'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPosts\\\\n\\\\n\\\\n\\\\n\\\\nArchive\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\nTags\\\\n\\\\n\\\\n\\\\n\\\\nFAQ\\\\n\\\\n\\\\n\\\\n\\\\nemojisearch.app\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n      LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\n \\\\n\\\\n\\\\nTable of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320866}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\\\nGenerative Agents Simulation#\\\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\\\n\\\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.')] \\n\\n    Here is the answer: \\n    According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [55.94s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:40:09.094992461Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 55938144495,\n",
      "          \"load_duration\": 867728,\n",
      "          \"prompt_eval_count\": 1732,\n",
      "          \"prompt_eval_duration\": 54698194000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1103114000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:40:09.094992461Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 55938144495,\n",
      "              \"load_duration\": 867728,\n",
      "              \"prompt_eval_count\": 1732,\n",
      "              \"prompt_eval_duration\": 54698194000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1103114000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3dfaf505-8e24-4ebf-853b-d5e56d85ff4e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [55.94s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader \n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation.\n",
    "    \n",
    "    Here are the facts:\n",
    "    {documents} \n",
    "\n",
    "    Here is the answer: \n",
    "    {generation}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df9f6944-4fee-4971-b3a7-2b81b44ed433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"generation\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"generation\": \"According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    According to the context, agent memory refers to the component that stores and retrieves information about past events or experiences. The memory mechanism surfaces the context to inform the agent's behavior, considering factors such as relevance, recency, and importance. \\n\\n    Here is the question: agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:40:47.055228574Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3993628558,\n",
      "          \"load_duration\": 720424,\n",
      "          \"prompt_eval_count\": 127,\n",
      "          \"prompt_eval_duration\": 2860013000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 997375000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:40:47.055228574Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3993628558,\n",
      "              \"load_duration\": 720424,\n",
      "              \"prompt_eval_count\": 127,\n",
      "              \"prompt_eval_duration\": 2860013000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 997375000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-64ca083e-07e6-4da5-ac30-3facf99b786d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader \n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     \n",
    "    Here is the answer:\n",
    "    {generation} \n",
    "\n",
    "    Here is the question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question,\"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c910c1-738c-4bf7-bf9e-801862b227eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gongai/anaconda3/envs/rag/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"llm agent memory\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"llm agent memory\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    llm agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.43s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:41:51.404069024Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4424771797,\n",
      "          \"load_duration\": 704220,\n",
      "          \"prompt_eval_count\": 124,\n",
      "          \"prompt_eval_duration\": 2947662000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 1341924000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:41:51.404069024Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4424771797,\n",
      "              \"load_duration\": 704220,\n",
      "              \"prompt_eval_count\": 124,\n",
      "              \"prompt_eval_duration\": 2947662000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 1341924000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-86805e22-6d1c-45f6-b4af-b563e5f8df48-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.43s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "{'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \n",
    "    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. \n",
    "    \n",
    "    Question to route: \n",
    "    {question}\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"llm agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023ff2db-eb4e-4d44-904c-ea061abc16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6",
   "metadata": {},
   "source": [
    "We'll implement these as a control flow in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents \n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "    \n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21594-00d4-48a8-ae2e-4e55a010b540",
   "metadata": {},
   "source": [
    "### Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9a4b9e4-3ba8-47d6-958c-e5a7112ac6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fff340-a45d-40e9-af70-c739ed7bd24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db243b86-f177-4f13-877a-1bd3a0a991be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "What are the types of agent memory?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [1.95s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:45:45.17481786Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 1943100459,\n",
      "          \"load_duration\": 897659,\n",
      "          \"prompt_eval_count\": 13,\n",
      "          \"prompt_eval_duration\": 431597000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 1372463000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:45:45.17481786Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 1943100459,\n",
      "              \"load_duration\": 897659,\n",
      "              \"prompt_eval_count\": 13,\n",
      "              \"prompt_eval_duration\": 431597000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 1372463000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-34caecf2-5e8e-40a8-9ecb-8518ab8f1a24-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [1.95s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [1.95s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"vectorstore\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:retrieve>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:retrieve>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1.95s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"generation\": null,\n",
      "  \"web_search\": null,\n",
      "  \"documents\": null\n",
      "}\n",
      "---RETRIEVE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve > chain:ChannelWrite<retrieve,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve > chain:ChannelWrite<retrieve,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve] [25ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: retrieve:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [8.43s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:45:53.631987112Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 8427238250,\n",
      "          \"load_duration\": 512684,\n",
      "          \"prompt_eval_count\": 316,\n",
      "          \"prompt_eval_duration\": 7284837000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1005653000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:45:53.631987112Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 8427238250,\n",
      "              \"load_duration\": 512684,\n",
      "              \"prompt_eval_count\": 316,\n",
      "              \"prompt_eval_duration\": 7284837000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1005653000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4abc0945-8126-49b8-a9e7-1097d8f64383-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [8.43s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [4.45s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:45:58.084053009Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4448916874,\n",
      "          \"load_duration\": 693248,\n",
      "          \"prompt_eval_count\": 132,\n",
      "          \"prompt_eval_duration\": 3289024000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1029004000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:45:58.084053009Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4448916874,\n",
      "              \"load_duration\": 693248,\n",
      "              \"prompt_eval_count\": 132,\n",
      "              \"prompt_eval_duration\": 3289024000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1029004000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-dd87f094-d905-46af-b147-117c84bc0f57-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [4.45s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \\\"dark\\\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \\\"dark\\\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \\\"dark\\\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [9.22s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:46:07.304579276Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 9217120659,\n",
      "          \"load_duration\": 842233,\n",
      "          \"prompt_eval_count\": 237,\n",
      "          \"prompt_eval_duration\": 8046200000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1040535000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:46:07.304579276Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 9217120659,\n",
      "              \"load_duration\": 842233,\n",
      "              \"prompt_eval_count\": 237,\n",
      "              \"prompt_eval_duration\": 8046200000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1040535000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-223315d7-c866-4845-bfea-44fc14995e82-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [9.22s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [8.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:46:15.847715171Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 8539702376,\n",
      "          \"load_duration\": 805829,\n",
      "          \"prompt_eval_count\": 224,\n",
      "          \"prompt_eval_duration\": 7340275000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1065662000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:46:15.847715171Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 8539702376,\n",
      "              \"load_duration\": 805829,\n",
      "              \"prompt_eval_count\": 224,\n",
      "              \"prompt_eval_duration\": 7340275000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1065662000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-dd57ce46-ab0c-4b7d-9e55-4947e123c4c9-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [8.54s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<grade_documents,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<grade_documents,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:decide_to_generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:decide_to_generate] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"generate\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<branch:grade_documents:decide_to_generate:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<branch:grade_documents:decide_to_generate:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents] [30.65s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: grade_documents:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: What are the types of agent memory? \\n    Context: [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320867}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320834}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320847}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \\\"dark\\\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\\\nComponent Two: Memory#\\\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\\\nTypes of Memory#\\\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\\\n\\\\n\\\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320848}, page_content='Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\\\n\\\\n\\\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\\\n\\\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 8. Categorization of human memory.\\\\nWe can roughly consider the following mappings:')] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [66.61s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:47:22.463644378Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 66610320713,\n",
      "          \"load_duration\": 805101,\n",
      "          \"prompt_eval_count\": 1496,\n",
      "          \"prompt_eval_duration\": 52099649000,\n",
      "          \"eval_count\": 81,\n",
      "          \"eval_duration\": 14370557000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:47:22.463644378Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 66610320713,\n",
      "              \"load_duration\": 805101,\n",
      "              \"prompt_eval_count\": 1496,\n",
      "              \"prompt_eval_duration\": 52099649000,\n",
      "              \"eval_count\": 81,\n",
      "              \"eval_duration\": 14370557000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-eadc3a19-0acc-4b33-a26f-fa28daa3fa07-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [66.61s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320867}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320834}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320847}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \\\"dark\\\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\\\nComponent Two: Memory#\\\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\\\nTypes of Memory#\\\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\\\n\\\\n\\\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'pk': 451152666323320848}, page_content='Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\\\n\\\\n\\\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\\\n\\\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 8. Categorization of human memory.\\\\nWe can roughly consider the following mappings:')] \\n\\n    Here is the answer: \\n    According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [56.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:48:19.108564995Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 56640712609,\n",
      "          \"load_duration\": 765776,\n",
      "          \"prompt_eval_count\": 1593,\n",
      "          \"prompt_eval_duration\": 55426015000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1072539000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:48:19.108564995Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 56640712609,\n",
      "              \"load_duration\": 765776,\n",
      "              \"prompt_eval_count\": 1593,\n",
      "              \"prompt_eval_duration\": 55426015000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1072539000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ca8d6e76-5cb1-4170-ab6b-7e9648e13d13-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [56.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"generation\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"generation\": \"According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    According to the provided context, there are two types of agent memory mentioned:\\n\\n1. Short-term memory: This is used for in-context learning and storing information temporarily.\\n2. Long-term memory: This provides the ability to retain and recall information over extended periods.\\n\\nAdditionally, the article mentions Sensory Memory as a type of human brain memory, which includes iconic, echoic, and haptic memories. \\n\\n    Here is the question: What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [6.52s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:48:25.62931052Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 6517242149,\n",
      "          \"load_duration\": 960162,\n",
      "          \"prompt_eval_count\": 165,\n",
      "          \"prompt_eval_duration\": 5357710000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1025742000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:48:25.62931052Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 6517242149,\n",
      "              \"load_duration\": 960162,\n",
      "              \"prompt_eval_count\": 165,\n",
      "              \"prompt_eval_duration\": 5357710000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1025742000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-956bec1c-425b-436d-abdc-9dec01b21ab2-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [6.52s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [63.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"useful\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [129.78s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [162.41s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "('According to the provided context, there are two types of agent memory '\n",
      " 'mentioned:\\n'\n",
      " '\\n'\n",
      " '1. Short-term memory: This is used for in-context learning and storing '\n",
      " 'information temporarily.\\n'\n",
      " '2. Long-term memory: This provides the ability to retain and recall '\n",
      " 'information over extended periods.\\n'\n",
      " '\\n'\n",
      " 'Additionally, the article mentions Sensory Memory as a type of human brain '\n",
      " 'memory, which includes iconic, echoic, and haptic memories.')\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733ab80-7e7b-4b1a-9519-9242de647eda",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/8d449b67-6bc4-4ecf-9153-759cd21df24f/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18712f81-e7f7-41c1-937d-8745c2ed003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c177a9f2-6bbc-420b-845f-75cef50fbc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts1 = time()\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Who are the Bears expected to draft first in the NFL draft?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])\n",
    "ts2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ee84a-89e1-44f8-8994-28124a5c7318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "Who are the Bears expected to draft first in the NFL draft?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    Who are the Bears expected to draft first in the NFL draft?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [870ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"web_search\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:06:56.164797Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 865271417,\n",
      "          \"load_duration\": 998542,\n",
      "          \"prompt_eval_count\": 138,\n",
      "          \"prompt_eval_duration\": 601310000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 260339000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"web_search\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:06:56.164797Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 865271417,\n",
      "              \"load_duration\": 998542,\n",
      "              \"prompt_eval_count\": 138,\n",
      "              \"prompt_eval_duration\": 601310000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 260339000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5b24a8c0-d47c-4edc-9415-6f32fd3a1045-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [875ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [876ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"websearch\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:websearch>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:websearch>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [877ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\",\n",
      "  \"generation\": null,\n",
      "  \"web_search\": null,\n",
      "  \"documents\": null\n",
      "}\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'Who are the Bears expected to draft first in the NFL draft?'}\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.callbacks.manager:Error in ConsoleCallbackHandler.on_tool_end callback: AttributeError(\"'list' object has no attribute 'strip'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [1.79s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.87s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:01.829506Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3853036959,\n",
      "          \"load_duration\": 2831750,\n",
      "          \"prompt_eval_count\": 562,\n",
      "          \"prompt_eval_duration\": 2317009000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1518313000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:01.829506Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3853036959,\n",
      "              \"load_duration\": 2831750,\n",
      "              \"prompt_eval_count\": 562,\n",
      "              \"prompt_eval_duration\": 2317009000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1518313000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4ec65274-3632-4a4a-94b3-002eb4d69657-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.88s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.66s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:04.507696Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2651274166,\n",
      "          \"load_duration\": 884083,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2425181000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 218463000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:04.507696Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2651274166,\n",
      "              \"load_duration\": 884083,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2425181000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 218463000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-02a1a75c-90e8-4cdc-a932-0dad3349fc22-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.67s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.67s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.55s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:08.246145Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3723004833,\n",
      "          \"load_duration\": 894125,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2189420000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1528060000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:08.246145Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3723004833,\n",
      "              \"load_duration\": 894125,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2189420000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1528060000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4ee44c0d-299f-414b-8c82-4f2b0c62743e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.73s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.65s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:10.903591Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2641114292,\n",
      "          \"load_duration\": 881833,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2427621000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207766000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:10.903591Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2641114292,\n",
      "              \"load_duration\": 881833,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2427621000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207766000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ef0cdee6-4c9a-4c69-91b4-5ded92c7e16f-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.39s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.72s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:14.633219Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3715633833,\n",
      "          \"load_duration\": 871417,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2190063000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1520408000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:14.633219Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3715633833,\n",
      "              \"load_duration\": 871417,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2190063000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1520408000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c239b910-2ff6-489d-8950-21eeaa08e211-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.73s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:17.278194Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2629146042,\n",
      "          \"load_duration\": 900625,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2414923000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208408000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:17.278194Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2629146042,\n",
      "              \"load_duration\": 900625,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2414923000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208408000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-13ef1cfe-ec4b-4298-b29d-fdb783a33b51-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:21.020536Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3724077125,\n",
      "          \"load_duration\": 920958,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2195713000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1521239000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:21.020536Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3724077125,\n",
      "              \"load_duration\": 920958,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2195713000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1521239000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-103b588f-2d74-4dca-b0d9-406559bb3ed8-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.74s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:23.676628Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2638764959,\n",
      "          \"load_duration\": 906875,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2420263000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 212788000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:23.676628Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2638764959,\n",
      "              \"load_duration\": 906875,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2420263000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 212788000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-072bdb97-6222-4cf1-82ee-160c0b5a7f6b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.39s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:27.388505Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3699568167,\n",
      "          \"load_duration\": 830875,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2180652000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1514095000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:27.388505Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3699568167,\n",
      "              \"load_duration\": 830875,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2180652000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1514095000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c6c2ffce-9b8a-40f9-a62a-a0b04a63a5ce-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:30.041153Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2629321917,\n",
      "          \"load_duration\": 836042,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2413741000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 209923000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:30.041153Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2629321917,\n",
      "              \"load_duration\": 836042,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2413741000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 209923000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ef05aa49-f607-4647-9214-bab5814c5ddf-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.72s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:33.769492Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3713510959,\n",
      "          \"load_duration\": 1116042,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2187961000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1519905000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:33.769492Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3713510959,\n",
      "              \"load_duration\": 1116042,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2187961000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1519905000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-770e9928-a9fd-41b4-84c8-4f337298f34c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.72s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.65s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:36.423836Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2637715417,\n",
      "          \"load_duration\": 871375,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2424633000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207728000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:36.423836Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2637715417,\n",
      "              \"load_duration\": 871375,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2424633000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207728000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3dd4e5ab-d45a-4483-b3c2-0b0a35f50080-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.66s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.38s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:40.168809Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3720429250,\n",
      "          \"load_duration\": 1403083,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2188823000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1523738000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:40.168809Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3720429250,\n",
      "              \"load_duration\": 1403083,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2188823000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1523738000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-172da892-1232-40a0-b132-1935f887fb1b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.74s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:42.822763Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2629545125,\n",
      "          \"load_duration\": 2211708,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2415642000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 206694000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:42.822763Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2629545125,\n",
      "              \"load_duration\": 2211708,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2415642000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 206694000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-68913122-29e2-4b2f-bf0a-c6006096d5d4-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.39s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:46.537603Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3692452292,\n",
      "          \"load_duration\": 1516417,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2176450000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1509385000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:46.537603Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3692452292,\n",
      "              \"load_duration\": 1516417,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2176450000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1509385000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-171108e7-8340-4f3d-b401-5e48d60145cf-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:49.17608Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2621724000,\n",
      "          \"load_duration\": 917125,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2408980000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207331000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:49.17608Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2621724000,\n",
      "              \"load_duration\": 917125,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2408980000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207331000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9a88320b-871b-4739-8903-3db040246b16-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.63s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.35s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:52.889113Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3694330250,\n",
      "          \"load_duration\": 1070208,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2175740000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1512738000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:52.889113Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3694330250,\n",
      "              \"load_duration\": 1070208,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2175740000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1512738000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-28b26d33-b556-45b6-97d6-e4dfebb92786-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:55.519622Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2625620292,\n",
      "          \"load_duration\": 938709,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2408167000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 211392000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:55.519622Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2625620292,\n",
      "              \"load_duration\": 938709,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2408167000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 211392000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-cbcb61b0-67d1-42c9-b127-61caa0bbd77b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.63s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.63s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.34s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:07:59.23357Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3696920792,\n",
      "          \"load_duration\": 809375,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2182804000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1509256000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:07:59.23357Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3696920792,\n",
      "              \"load_duration\": 809375,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2182804000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1509256000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-afc7f0cf-839b-47d4-86c0-6d4bf2bc3e09-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:01.881143Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2624979750,\n",
      "          \"load_duration\": 1399042,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2409597000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 206964000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:01.881143Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2624979750,\n",
      "              \"load_duration\": 1399042,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2409597000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 206964000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-dd220d78-a466-4c33-bed5-a1eb207d8a45-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:05.604435Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3692143834,\n",
      "          \"load_duration\": 1456750,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2176545000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1507532000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:05.604435Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3692143834,\n",
      "              \"load_duration\": 1456750,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2176545000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1507532000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9b8bdba9-77eb-47ad-a2b2-e5911505cb32-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:08.253142Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2627471625,\n",
      "          \"load_duration\": 1390875,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2412363000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208357000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:08.253142Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2627471625,\n",
      "              \"load_duration\": 1390875,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2412363000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208357000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-56f6bb6f-16b5-4dc5-8f80-e85715e0cf4d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:11.973307Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3697019792,\n",
      "          \"load_duration\": 1292292,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2177340000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1512290000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:11.973307Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3697019792,\n",
      "              \"load_duration\": 1292292,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2177340000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1512290000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a9f174e5-099f-4f6c-81b2-75ff8294f236-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:14.623534Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2626295834,\n",
      "          \"load_duration\": 1475709,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2410678000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207849000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:14.623534Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2626295834,\n",
      "              \"load_duration\": 1475709,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2410678000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207849000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a3000002-4984-45e5-bed3-bd5e3a939740-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.69s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:18.330784Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3688174041,\n",
      "          \"load_duration\": 1032666,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2175353000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1506773000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:18.330784Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3688174041,\n",
      "              \"load_duration\": 1032666,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2175353000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1506773000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-19f78c85-3c84-4a41-a94c-b6596086fc50-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:20.967128Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2623119833,\n",
      "          \"load_duration\": 802667,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2409021000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208999000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:20.967128Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2623119833,\n",
      "              \"load_duration\": 802667,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2409021000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208999000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b4702299-e383-4560-9f81-053e15062022-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.34s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:24.674165Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3687037916,\n",
      "          \"load_duration\": 1368125,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2177355000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1502925000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:24.674165Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3687037916,\n",
      "              \"load_duration\": 1368125,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2177355000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1502925000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f87b3962-2cb7-41a8-ac85-a6ea4fea315d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:27.330086Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2629917125,\n",
      "          \"load_duration\": 1466875,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2414938000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207713000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:27.330086Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2629917125,\n",
      "              \"load_duration\": 1466875,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2414938000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207713000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ec6fe4b9-6cb1-490a-8920-5b3cd1cc14cc-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:31.036746Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3694046833,\n",
      "          \"load_duration\": 950916,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2182175000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1505497000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:31.036746Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3694046833,\n",
      "              \"load_duration\": 950916,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2182175000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1505497000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-48d5cd08-fad2-449c-8a69-ba5690875811-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:33.681164Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2623548584,\n",
      "          \"load_duration\": 1372375,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2411505000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 205373000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:33.681164Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2623548584,\n",
      "              \"load_duration\": 1372375,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2411505000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 205373000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-98dba185-91d1-4acc-8fb7-97ac6e09fc76-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.35s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:37.387111Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3688054833,\n",
      "          \"load_duration\": 906791,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2175030000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1508045000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:37.387111Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3688054833,\n",
      "              \"load_duration\": 906791,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2175030000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1508045000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-7530ddd4-fa59-42e1-b7d4-4d1bc2a48f07-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:40.036592Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2624755709,\n",
      "          \"load_duration\": 928250,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2409473000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 209129000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:40.036592Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2624755709,\n",
      "              \"load_duration\": 928250,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2409473000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 209129000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5cb176e2-e3d3-4a80-8dec-2c3257b5346d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.35s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.72s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:43.757246Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3703002667,\n",
      "          \"load_duration\": 803208,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2177310000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1520686000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:43.757246Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3703002667,\n",
      "              \"load_duration\": 803208,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2177310000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1520686000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-fba7831d-f9ca-41ea-a1a5-4c78891960a0-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.72s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:46.401103Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2620938333,\n",
      "          \"load_duration\": 827250,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2407693000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207682000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:46.401103Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2620938333,\n",
      "              \"load_duration\": 827250,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2407693000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207682000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-372b1ff9-54b3-4211-9817-1730aa2181ca-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:50.114217Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3691137042,\n",
      "          \"load_duration\": 1534125,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2182583000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1501634000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:50.114217Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3691137042,\n",
      "              \"load_duration\": 1534125,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2182583000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1501634000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-72c5a4c7-7da7-40ec-b2e1-3a72707436cb-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:52.764036Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2625095042,\n",
      "          \"load_duration\": 1313875,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2409059000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 209029000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:52.764036Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2625095042,\n",
      "              \"load_duration\": 1313875,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2409059000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 209029000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4878d693-6438-490a-9f4a-9b30785f64a1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [6ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:56.498899Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3702815833,\n",
      "          \"load_duration\": 1392167,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2186567000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1508621000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:56.498899Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3702815833,\n",
      "              \"load_duration\": 1392167,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2186567000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1508621000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-6cc7659c-df89-49ea-8643-420db0b7bdc1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.72s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:08:59.132465Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2620867042,\n",
      "          \"load_duration\": 766000,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2406957000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208835000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:08:59.132465Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2620867042,\n",
      "              \"load_duration\": 766000,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2406957000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208835000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e3e10d39-034d-477e-ba6d-e7d4dd48825e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:02.853224Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3694474458,\n",
      "          \"load_duration\": 1396875,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2178069000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1508948000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:02.853224Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3694474458,\n",
      "              \"load_duration\": 1396875,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2178069000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1508948000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5bccbbac-3eb5-44c6-ac7e-dbb1624e8a88-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:05.504162Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2625869416,\n",
      "          \"load_duration\": 1527833,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2408560000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 209310000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:05.504162Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2625869416,\n",
      "              \"load_duration\": 1527833,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2408560000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 209310000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b00618f3-74ec-4f60-ae21-5efc5828adc3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:09.210383Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3691485166,\n",
      "          \"load_duration\": 841500,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2182068000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1504519000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:09.210383Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3691485166,\n",
      "              \"load_duration\": 841500,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2182068000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1504519000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-73a9d2e5-7f4f-42bc-971d-746e83a0f319-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.70s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:11.847678Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2624864000,\n",
      "          \"load_duration\": 802250,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2411235000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208418000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:11.847678Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2624864000,\n",
      "              \"load_duration\": 802250,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2411235000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208418000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f4da4ba5-4207-4dc8-964b-819a802e62fa-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.34s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:15.556831Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3691073375,\n",
      "          \"load_duration\": 1015458,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2177585000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1507706000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:15.556831Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3691073375,\n",
      "              \"load_duration\": 1015458,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2177585000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1507706000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-eeef68db-d403-4553-8591-a7048772c55d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:18.204032Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2624135834,\n",
      "          \"load_duration\": 1434709,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2409036000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 207581000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:18.204032Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2624135834,\n",
      "              \"load_duration\": 1434709,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2409036000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 207581000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8317bc1f-9f03-46af-9a80-3099608e6f57-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:21.923983Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3692493084,\n",
      "          \"load_duration\": 1419292,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2180558000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1503873000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:21.923983Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3692493084,\n",
      "              \"load_duration\": 1419292,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2180558000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1503873000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-94726fb7-b12d-4de4-8e30-60509009a01a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:24.575497Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2623800334,\n",
      "          \"load_duration\": 1349084,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2408410000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 208307000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:24.575497Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2623800334,\n",
      "              \"load_duration\": 1349084,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2408410000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 208307000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-520ec29a-c27c-4a86-ab1f-763bcee2ee11-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [3.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:28.295839Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 3689759833,\n",
      "          \"load_duration\": 1936125,\n",
      "          \"prompt_eval_count\": 563,\n",
      "          \"prompt_eval_duration\": 2176987000,\n",
      "          \"eval_count\": 45,\n",
      "          \"eval_duration\": 1505154000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:28.295839Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 3689759833,\n",
      "              \"load_duration\": 1936125,\n",
      "              \"prompt_eval_count\": 563,\n",
      "              \"prompt_eval_duration\": 2176987000,\n",
      "              \"eval_count\": 45,\n",
      "              \"eval_duration\": 1505154000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-76758db8-3324-4344-ae4c-5ed5122d3c2a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"The Chicago Bears made waves during the first round of the 2024 NFL draft, where they added two blue chip players to the roster with their top-10 selections — quarterback Caleb Williams (No. 1 ...\\\\n8:27 p.m.: Caleb Williams reacts energetically to Bears drafting Rome Odunze. Close to an hour after the Bears drafted Caleb Williams with the No. 1 pick in the 2024 NFL Draft, they remained at their No. 9 pick to take Washington wide receiver Rome Odunze. And the Bears' new quarterback offered an energetic response while watching backstage.\\\\nHere's a full list of the Bears picks- as things stand right now- for the 2024 NFL Draft: First round: No. 1 overall (via Carolina) First round: No. 9 overall\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\")] \\n\\n    Here is the answer: \\n    The Chicago Bears are not expected to draft anyone first in the NFL draft because they already made their selection, drafting USC quarterback Caleb Williams with the No. 1 pick. They have no additional picks in the first round.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-06-13T11:09:30.943234Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 2627929500,\n",
      "          \"load_duration\": 1316750,\n",
      "          \"prompt_eval_count\": 622,\n",
      "          \"prompt_eval_duration\": 2410888000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 209390000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-06-13T11:09:30.943234Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 2627929500,\n",
      "              \"load_duration\": 1316750,\n",
      "              \"prompt_eval_count\": 622,\n",
      "              \"prompt_eval_duration\": 2410888000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 209390000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-878ed437-4282-4b39-8428-c5bf39313721-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [6.36s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:LangGraph] [155.66s] Chain run errored with error:\n",
      "\u001b[0m\"GraphRecursionError('Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.')Traceback (most recent call last):\\n\\n\\n  File \\\"/Users/stephen/Library/Caches/pypoetry/virtualenvs/milvus-bootcamp-rag-MiiP0ihC-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py\\\", line 1014, in stream\\n    raise GraphRecursionError(\\n\\n\\nlanggraph.errors.GraphRecursionError: Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\"\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are the Bears expected to draft first in the NFL draft?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFinished running: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/milvus-bootcamp-rag-MiiP0ihC-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1014\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(read_channels(channels, output_keys))\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "print(f\"Elapsed time: {(ts2-ts1):.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9051bea-13fa-4eb3-b671-16f59755931d",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/c785f9c0-f519-4a38-ad5a-febb59a2139c/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ac34852-3b21-477a-a576-45466722171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "Is CrewAI a good multi-agent framework?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    Is CrewAI a good multi-agent framework?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [4.67s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"web_search\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:52:08.908441266Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4665310678,\n",
      "          \"load_duration\": 958991,\n",
      "          \"prompt_eval_count\": 129,\n",
      "          \"prompt_eval_duration\": 3193145000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 1341673000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"web_search\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:52:08.908441266Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4665310678,\n",
      "              \"load_duration\": 958991,\n",
      "              \"prompt_eval_count\": 129,\n",
      "              \"prompt_eval_duration\": 3193145000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 1341673000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ad98f35d-63d0-4642-b80e-28f8991c698b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [4.67s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [4.67s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"websearch\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:websearch>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<branch:__start__:route_question:websearch>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [4.67s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\",\n",
      "  \"generation\": null,\n",
      "  \"web_search\": null,\n",
      "  \"documents\": null\n",
      "}\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'Is CrewAI a good multi-agent framework?'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] [1.59s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'url': 'https://yeyu.substack.com/p/for-a-multi-agent-framework-crewai', 'content': 'These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\u200a—\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\n Step 2\\u200a—\\u200aImport and Setup\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.'}, {'url': 'https://sajalsharma.com/posts/overview-multi-agent-fameworks/', 'content': \"We'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\"}, {'url': 'https://www.concision.ai/blog/comparing-multi-agent-ai-frameworks-crewai-langgraph-autogpt-autogen', 'content': \"Let's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\"}, {'url': 'https://medium.com/@ndimeshi/crewai-a-multi-agentic-framework-for-efficient-task-management-46bc4f1ee0c6', 'content': \"CrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\"}, {'url': 'https://www.gettingstarted.ai/autogen-vs-crewai/', 'content': 'AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.'}]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [1.60s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Is CrewAI a good multi-agent framework? \\n    Context: [Document(page_content=\\\"These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nWe'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nAutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [30.48s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:52:40.994297861Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 30475780900,\n",
      "          \"load_duration\": 1993452,\n",
      "          \"prompt_eval_count\": 557,\n",
      "          \"prompt_eval_duration\": 15700575000,\n",
      "          \"eval_count\": 84,\n",
      "          \"eval_duration\": 14632190000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:52:40.994297861Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 30475780900,\n",
      "              \"load_duration\": 1993452,\n",
      "              \"prompt_eval_count\": 557,\n",
      "              \"prompt_eval_duration\": 15700575000,\n",
      "              \"eval_count\": 84,\n",
      "              \"eval_duration\": 14632190000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4d09e511-20f0-4d51-aced-8031138610d6-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [30.48s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nWe'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nAutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.\\\")] \\n\\n    Here is the answer: \\n    According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [25.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:53:05.999853761Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 25001436676,\n",
      "          \"load_duration\": 625330,\n",
      "          \"prompt_eval_count\": 657,\n",
      "          \"prompt_eval_duration\": 23754246000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1111455000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:53:05.999853761Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 25001436676,\n",
      "              \"load_duration\": 625330,\n",
      "              \"prompt_eval_count\": 657,\n",
      "              \"prompt_eval_duration\": 23754246000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1111455000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-72df4a7f-35d2-465f-8e35-1065edd6902a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [25.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\",\n",
      "  \"generation\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\",\n",
      "  \"generation\": \"According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    According to the context, CrewAI is ideal for environments that require production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, making it suitable for certain use cases. However, I don't know if it's considered a \\\"good\\\" multi-agent framework in general, as the context only provides specific advantages and ideal use cases for CrewAI. \\n\\n    Here is the question: Is CrewAI a good multi-agent framework?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [6.77s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:53:12.771050075Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 6767728066,\n",
      "          \"load_duration\": 552410,\n",
      "          \"prompt_eval_count\": 169,\n",
      "          \"prompt_eval_duration\": 5600427000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1036846000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:53:12.771050075Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 6767728066,\n",
      "              \"load_duration\": 552410,\n",
      "              \"prompt_eval_count\": 169,\n",
      "              \"prompt_eval_duration\": 5600427000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1036846000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-05c7d41c-d77d-4f10-a6aa-a70407122eb2-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [6.77s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [31.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not useful\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:websearch>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<branch:generate:grade_generation_v_documents_and_question:websearch>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [62.26s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'Is CrewAI a good multi-agent framework?'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] [6.01s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'url': 'https://sajalsharma.com/posts/overview-multi-agent-fameworks/', 'content': \"We'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\"}, {'url': 'https://yeyu.substack.com/p/for-a-multi-agent-framework-crewai', 'content': 'These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\u200a—\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\n Step 2\\u200a—\\u200aImport and Setup\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.'}, {'url': 'https://www.concision.ai/blog/comparing-multi-agent-ai-frameworks-crewai-langgraph-autogpt-autogen', 'content': \"Let's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\"}, {'url': 'https://medium.com/@ndimeshi/crewai-a-multi-agentic-framework-for-efficient-task-management-46bc4f1ee0c6', 'content': \"CrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\"}, {'url': 'https://github.com/crewAIInc/crewAI', 'content': \"CrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you're building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\"}]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [6.01s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Is CrewAI a good multi-agent framework? \\n    Context: [Document(page_content=\\\"These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nWe'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nAutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.\\\"), Document(page_content=\\\"We'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nThese three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you're building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [47.45s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:54:06.246375771Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 47450893797,\n",
      "          \"load_duration\": 1984375,\n",
      "          \"prompt_eval_count\": 1038,\n",
      "          \"prompt_eval_duration\": 34891748000,\n",
      "          \"eval_count\": 70,\n",
      "          \"eval_duration\": 12417098000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:54:06.246375771Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 47450893797,\n",
      "              \"load_duration\": 1984375,\n",
      "              \"prompt_eval_count\": 1038,\n",
      "              \"prompt_eval_duration\": 34891748000,\n",
      "              \"eval_count\": 70,\n",
      "              \"eval_duration\": 12417098000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-98da0e2a-d61e-4a76-adc4-81d78bfcd883-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [47.46s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(page_content=\\\"These three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nWe'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nAutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.\\\"), Document(page_content=\\\"We'll also explore three leading frameworks—AutoGen, CrewAI, and LangGraph—comparing their features, autonomy levels, and ideal use cases, before concluding with strategic recommendations for adopting these frameworks. The Building Blocks of Multi-Agent Systems. Multi-agent systems are akin to a functional team, where each member (agent ...\\\\nThese three sections are easy to understand by their names, where the role refers to the name of the agent, the goal refers to the reason for creating this agent, and the backstory of what the agent is capable of. Lab For AI\\\\nFor a Multi-Agent Framework, CrewAI has its Advantages Compared to AutoGen\\\\nA Quick Guide to the App Development with CrewAI and its comparison to AutoGen\\\\nAs it becomes increasingly apparent, leveraging a multi-agent architecture in the construction of LLM-powered applications performs superiorly compared to a solo agent\\\\u200a—\\\\u200aeven with impeccable prompting strategies. To prove the ease of the agent orchestration for a sequential task, I am going to assign to the agent group the same task as my previous AutoGen demonstration which asks AI agents to generate a travel plan with proper activities considering the weather conditions and attached insurance item list.\\\\n Step 2\\\\u200a—\\\\u200aImport and Setup\\\\nSince the low-level implementation relies on the LangChain library, we must import the relevant LangChain packages in addition to the CrewAI.\\\\n In the sequential strategy which is the only choice right now, the orders in the agents list and tasks list are exactly the task execution order of these agents.\\\\nLet's explore some of the top multi-agent frameworks and discuss the main advantages and disadvantages of each. CrewAI . Ideal for environments that require production-grade applications with methodical task distribution and dependable implementation, and where the integration of framework analytics is not a concern. Pros:\\\\nCrewAI is built around three main concepts: agents, tasks, and processes. Each of these components plays a critical role in ensuring the framework's effectiveness. Agents: The Core Players\\\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you're building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\\")] \\n\\n    Here is the answer: \\n    Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [41.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:54:47.497973259Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 41246686084,\n",
      "          \"load_duration\": 555262,\n",
      "          \"prompt_eval_count\": 1123,\n",
      "          \"prompt_eval_duration\": 40022844000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1089116000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:54:47.497973259Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 41246686084,\n",
      "              \"load_duration\": 555262,\n",
      "              \"prompt_eval_count\": 1123,\n",
      "              \"prompt_eval_duration\": 40022844000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1089116000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-6603c4bb-4c0d-435c-839b-15ec63b5718d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [41.25s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\",\n",
      "  \"generation\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Is CrewAI a good multi-agent framework?\",\n",
      "  \"generation\": \"Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    Based on the provided context, it seems that CrewAI is considered a good multi-agent framework, particularly suitable for environments requiring production-grade applications with methodical task distribution and dependable implementation. It's built around three main concepts: agents, tasks, and processes, which enables AI agents to assume roles, share goals, and operate in a cohesive unit. \\n\\n    Here is the question: Is CrewAI a good multi-agent framework?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [6.85s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3\",\n",
      "          \"created_at\": \"2024-07-15T02:54:54.3478165Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 6845907525,\n",
      "          \"load_duration\": 625325,\n",
      "          \"prompt_eval_count\": 155,\n",
      "          \"prompt_eval_duration\": 5698700000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 1015322000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3\",\n",
      "              \"created_at\": \"2024-07-15T02:54:54.3478165Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 6845907525,\n",
      "              \"load_duration\": 625325,\n",
      "              \"prompt_eval_count\": 155,\n",
      "              \"prompt_eval_duration\": 5698700000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 1015322000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ec40401f-daf0-4094-89a9-876ada149377-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [6.85s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [48.10s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"useful\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [95.56s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [170.12s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "('Based on the provided context, it seems that CrewAI is considered a good '\n",
      " 'multi-agent framework, particularly suitable for environments requiring '\n",
      " 'production-grade applications with methodical task distribution and '\n",
      " \"dependable implementation. It's built around three main concepts: agents, \"\n",
      " 'tasks, and processes, which enables AI agents to assume roles, share goals, '\n",
      " 'and operate in a cohesive unit.')\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "ts1 = time()\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Is CrewAI a good multi-agent framework?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])\n",
    "ts2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3d3aba-9720-4252-8539-19db047c136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 170.12 sec\n"
     ]
    }
   ],
   "source": [
    "print(f\"Elapsed time: {(ts2-ts1):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517a311-f2f4-42e7-8a77-87ec98efbc03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
